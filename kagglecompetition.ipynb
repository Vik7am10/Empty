{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPvvqemIDMAziUwPpHEWDoy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vik7am10/Empty/blob/main/kagglecompetition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten, Concatenate, BatchNormalization, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.regularizers import l2, l1_l2\n",
        "from tensorflow.keras.layers import Add\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "zbIDyYvdcWA5"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# Path to the ZIP file\n",
        "zip_file_path = '/content/cs-480-2024-spring.zip'\n",
        "\n",
        "# Directory to unzip to\n",
        "unzip_dir = '/content/data'\n",
        "\n",
        "# Final target directory\n",
        "target_dir = '/content/target_folder'\n",
        "\n",
        "# Step 1: Unzip the file\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(unzip_dir)\n",
        "\n",
        "# Step 2: Move the unzipped contents to the target directory\n",
        "if not os.path.exists(target_dir):\n",
        "    os.makedirs(target_dir)\n",
        "\n",
        "for filename in os.listdir(unzip_dir):\n",
        "    shutil.move(os.path.join(unzip_dir, filename), target_dir)\n",
        "\n",
        "# Step 3: Clean up the temporary directory\n",
        "shutil.rmtree(unzip_dir)\n",
        "\n"
      ],
      "metadata": {
        "id": "9dyvRWTjwtre",
        "collapsed": true
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CSV and TSV files\n",
        "train_df = pd.read_csv('/content/target_folder/data/train.csv')\n",
        "target_columns = [col for col in train_df.columns if 'X' in col]\n",
        "ancillary_columns = [col for col in train_df.columns if col not in ['id'] + target_columns]\n",
        "\n",
        "# Define the batch size\n",
        "batch_size = 43363\n",
        "num_batches = len(train_df) // batch_size + (1 if len(train_df) % batch_size != 0 else 0)\n",
        "anc_size = len(ancillary_columns)\n",
        "df_size = len(train_df)\n",
        "\n",
        "print(f\"Number of batches: {num_batches}\")\n",
        "print(f\"Ancillary: {anc_size}\")\n",
        "print(f\"DF: {df_size}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0L2oxAzlyWLG",
        "outputId": "809be3d8-dd98-4b3b-c314-71f627f7e7a5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of batches: 1\n",
            "Ancillary: 151\n",
            "DF: 43363\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to load and preprocess images\n",
        "def preprocess_image(image_path):\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    image = tf.image.resize(image, [64, 64])  # Resize to 64x64 for ResNet50\n",
        "    image = tf.image.random_flip_left_right(image)  # Random horizontal flip\n",
        "    image = tf.image.random_flip_up_down(image)  # Random vertical flip\n",
        "    image = tf.image.random_brightness(image, max_delta=0.1)  # Random brightness\n",
        "    image = tf.image.random_contrast(image, lower=0.8, upper=1.2)  # Random contrast\n",
        "    image = tf.image.random_saturation(image, lower=0.8, upper=1.2)  # Random saturation\n",
        "    image = tf.image.random_hue(image, max_delta=0.1)  # Random hue\n",
        "    image = image / 255.0  # Normalize to [0, 1]\n",
        "    return image.numpy()  # Convert to numpy array\n",
        "\n",
        "# processing the first and only batch\n",
        "batch_idx = 0\n",
        "start_idx = batch_idx * batch_size\n",
        "end_idx = min((batch_idx + 1) * batch_size, len(train_df))\n",
        "\n",
        "batch_image_ids = train_df['id'].iloc[start_idx:end_idx]\n",
        "\n",
        "# Load images for the current batch\n",
        "image_paths = [os.path.join('/content/target_folder/data/train_images', f'{img_id}.jpeg') for img_id in batch_image_ids]\n",
        "train_images = np.array([preprocess_image(path) for path in image_paths])\n",
        "\n",
        "# Extract corresponding ancillary data and targets\n",
        "X_ancillary_batch = train_df[ancillary_columns].iloc[start_idx:end_idx].values\n",
        "y_train_batch = train_df[target_columns].iloc[start_idx:end_idx].values\n",
        "\n",
        "# Normalize ancillary data\n",
        "scaler_ancillary = StandardScaler()\n",
        "X_ancillary_batch = scaler_ancillary.fit_transform(X_ancillary_batch)\n",
        "\n",
        "# Normalize target data\n",
        "scaler_target = MinMaxScaler()\n",
        "y_train_batch = scaler_target.fit_transform(y_train_batch)"
      ],
      "metadata": {
        "id": "YbrkjRkmeXLA"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model architecture with minimal changes\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(64, 64, 3))\n",
        "base_model.trainable = True\n",
        "\n",
        "inputs = Input(shape=(64, 64, 3))\n",
        "x = base_model(inputs, training=True)\n",
        "x = Flatten()(x)\n",
        "x = Dense(128, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.35)(x)\n",
        "image_features = Dense(64, activation='relu')(x)\n",
        "\n",
        "ancillary_input = Input(shape=(X_ancillary_batch.shape[1],))\n",
        "ancillary_features = Dense(64, activation='relu', kernel_regularizer=l2(0.01))(ancillary_input)\n",
        "ancillary_features = BatchNormalization()(ancillary_features)\n",
        "ancillary_features = Dropout(0.35)(ancillary_features)\n",
        "\n",
        "combined_features = Concatenate()([image_features, ancillary_features])\n",
        "combined_features = Dense(64, activation='relu')(combined_features)\n",
        "combined_features = Add()([combined_features, image_features])\n",
        "combined_features = BatchNormalization()(combined_features)\n",
        "combined_features = Dropout(0.35)(combined_features)\n",
        "output = Dense(len(target_columns), activation='linear')(combined_features)\n",
        "\n",
        "model = Model(inputs=[inputs, ancillary_input], outputs=output)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='mean_squared_error')  # Slightly increased learning rate\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.1, patience=3, min_lr=1e-7, verbose=1)\n",
        "early_stop = EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 802
        },
        "collapsed": true,
        "id": "zqaLihoSyjuj",
        "outputId": "344f3b33-233c-424b-c562-e3d5d542bde4"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_18\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_18\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_57            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ resnet50 (\u001b[38;5;33mFunctional\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │     \u001b[38;5;34m23,587,712\u001b[0m │ input_layer_57[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_19 (\u001b[38;5;33mFlatten\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8192\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ resnet50[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_97 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │      \u001b[38;5;34m2,097,408\u001b[0m │ flatten_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_58            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m151\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_61    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │          \u001b[38;5;34m1,024\u001b[0m │ dense_97[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_99 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │          \u001b[38;5;34m9,728\u001b[0m │ input_layer_58[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_61 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_6… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_62    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │            \u001b[38;5;34m256\u001b[0m │ dense_99[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_98 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m16,448\u001b[0m │ dropout_61[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_62 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_6… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_16            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dense_98[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ dropout_62[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_100 (\u001b[38;5;33mDense\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │          \u001b[38;5;34m8,256\u001b[0m │ concatenate_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_5 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ dense_100[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                           │                        │                │ dense_98[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_63    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │            \u001b[38;5;34m256\u001b[0m │ add_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_63 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_6… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_101 (\u001b[38;5;33mDense\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)             │          \u001b[38;5;34m1,170\u001b[0m │ dropout_63[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_57            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ resnet50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> │ input_layer_57[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8192</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ resnet50[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_97 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,097,408</span> │ flatten_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_58            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">151</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_61    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ dense_97[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_99 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">9,728</span> │ input_layer_58[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_61 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_6… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_62    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ dense_99[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_98 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │ dropout_61[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_62 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_6… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_16            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_98[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ dropout_62[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_100 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ concatenate_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_100[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                           │                        │                │ dense_98[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_63    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ add_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_63 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_6… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_101 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,170</span> │ dropout_63[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m25,722,258\u001b[0m (98.12 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,722,258</span> (98.12 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m25,668,370\u001b[0m (97.92 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,668,370</span> (97.92 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m53,888\u001b[0m (210.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">53,888</span> (210.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Augmentation\n",
        "data_gen = ImageDataGenerator(\n",
        "    rotation_range=20,  # Increased rotation range\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    zoom_range=0.2\n",
        ")\n",
        "\n",
        "# Training Data Generator\n",
        "def train_generator(X_img, X_anc, y, batch_size=64):\n",
        "    data_gen_flow = data_gen.flow(X_img, y, batch_size=batch_size, shuffle=True)\n",
        "    while True:\n",
        "        for X_batch, y_batch in data_gen_flow:\n",
        "            start = 0\n",
        "            end = len(X_batch)\n",
        "            ancillary_batch = X_anc[start:end]\n",
        "            yield (tf.convert_to_tensor(X_batch, dtype=tf.float32),\n",
        "                   tf.convert_to_tensor(ancillary_batch, dtype=tf.float32)), \\\n",
        "                   tf.convert_to_tensor(y_batch, dtype=tf.float32)\n",
        "\n",
        "# Prepare Dataset\n",
        "train_dataset = tf.data.Dataset.from_generator(\n",
        "    lambda: train_generator(train_images, X_ancillary_batch, y_train_batch, batch_size=64),\n",
        "    output_signature=(\n",
        "        (tf.TensorSpec(shape=(None, 64, 64, 3), dtype=tf.float32),\n",
        "         tf.TensorSpec(shape=(None, X_ancillary_batch.shape[1]), dtype=tf.float32)),\n",
        "        tf.TensorSpec(shape=(None, y_train_batch.shape[1]), dtype=tf.float32)\n",
        "    )\n",
        ")\n",
        "\n",
        "# Train the Model\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    steps_per_epoch=len(train_images) // 64,\n",
        "    epochs=15,\n",
        "    callbacks=[reduce_lr, early_stop]\n",
        ")\n",
        "\n",
        "# Save model weights\n",
        "model.save_weights(f\"model_after_batch_{batch_idx}.weights.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "HMYM-2RDypB2",
        "outputId": "050111a7-f4e2-4552-d420-8e0d7a35c26e"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m677/677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 86ms/step - loss: 7.0722 - learning_rate: 1.0000e-04\n",
            "Epoch 2/15\n",
            "\u001b[1m677/677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 85ms/step - loss: 3.4655 - learning_rate: 1.0000e-04\n",
            "Epoch 3/15\n",
            "\u001b[1m677/677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 85ms/step - loss: 1.5564 - learning_rate: 1.0000e-04\n",
            "Epoch 4/15\n",
            "\u001b[1m677/677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 85ms/step - loss: 0.7896 - learning_rate: 1.0000e-04\n",
            "Epoch 5/15\n",
            "\u001b[1m677/677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 85ms/step - loss: 0.5041 - learning_rate: 1.0000e-04\n",
            "Epoch 6/15\n",
            "\u001b[1m677/677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 87ms/step - loss: 0.3935 - learning_rate: 1.0000e-04\n",
            "Epoch 7/15\n",
            "\u001b[1m677/677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 86ms/step - loss: 0.3126 - learning_rate: 1.0000e-04\n",
            "Epoch 8/15\n",
            "\u001b[1m677/677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 86ms/step - loss: 0.2671 - learning_rate: 1.0000e-04\n",
            "Epoch 9/15\n",
            "\u001b[1m677/677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 86ms/step - loss: 0.2223 - learning_rate: 1.0000e-04\n",
            "Epoch 10/15\n",
            "\u001b[1m677/677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 87ms/step - loss: 0.1908 - learning_rate: 1.0000e-04\n",
            "Epoch 11/15\n",
            "\u001b[1m677/677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 86ms/step - loss: 0.1642 - learning_rate: 1.0000e-04\n",
            "Epoch 12/15\n",
            "\u001b[1m677/677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 87ms/step - loss: 0.1317 - learning_rate: 1.0000e-04\n",
            "Epoch 13/15\n",
            "\u001b[1m677/677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 87ms/step - loss: 0.1164 - learning_rate: 1.0000e-04\n",
            "Epoch 14/15\n",
            "\u001b[1m677/677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 87ms/step - loss: 0.1012 - learning_rate: 1.0000e-04\n",
            "Epoch 15/15\n",
            "\u001b[1m677/677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 85ms/step - loss: 0.0815 - learning_rate: 1.0000e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the final trained model weights\n",
        "model.load_weights(f\"model_after_batch_0.weights.h5\")\n",
        "\n",
        "# Preprocess and load all test images\n",
        "test_df = pd.read_csv('/content/target_folder/data/test.csv')\n",
        "test_image_ids = test_df['id'].values\n",
        "test_image_paths = [os.path.join('/content/target_folder/data/test_images', f'{img_id}.jpeg') for img_id in test_image_ids]\n",
        "test_images = np.array([preprocess_image(path) for path in test_image_paths])\n",
        "\n",
        "# Standardize ancillary data for test set\n",
        "X_test_ancillary = test_df[ancillary_columns].values\n",
        "X_test_ancillary = scaler_ancillary.transform(X_test_ancillary)\n",
        "\n",
        "# Predict on the entire test set\n",
        "predictions_log = model.predict([test_images, X_test_ancillary])\n",
        "\n",
        "# Reverse the normalization on predictions\n",
        "predictions = scaler_target.inverse_transform(predictions_log)\n",
        "\n",
        "# Unnormalize the predictions if necessary\n",
        "predictions_unnormalized = predictions\n",
        "\n",
        "# Select the first and last 6 columns for the output\n",
        "selected_columns = target_columns[:6] + target_columns[-6:]\n",
        "predictions_selected = pd.DataFrame(predictions_unnormalized, columns=target_columns)[selected_columns]\n",
        "\n",
        "# Add 'id' column for identification\n",
        "predictions_selected['id'] = test_df['id']\n",
        "predictions_selected = predictions_selected[['id'] + selected_columns]\n",
        "\n",
        "# Save the selected predictions to a CSV file\n",
        "predictions_selected.to_csv('predictions_selected.csv', index=False)\n",
        "\n",
        "print(\"Predictions for all test images have been generated, unnormalized, and saved.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "458QuIwtL-EY",
        "outputId": "4642014f-5a8f-4fc6-9e28-3ff2af13f473"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step\n",
            "Predictions for all test images have been generated, unnormalized, and saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_filtered = predictions_selected.iloc[:, [0] + list(range(-6, 0))]\n",
        "df_filtered.to_csv('submission.csv', index=False)"
      ],
      "metadata": {
        "id": "YS463gwnJ4nO"
      },
      "execution_count": 94,
      "outputs": []
    }
  ]
}